{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling recipe ingredients with non-negative matrix factorization\n",
    "\n",
    "Use non-negative matrix factorization to extract themes from ingredients.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-13T20:58:22.976930Z",
     "start_time": "2017-07-13T20:58:22.774974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from numpy.random import rand, RandomState\n",
    "from numpy import array, matrix, linalg\n",
    "from nltk import word_tokenize \n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-13T20:58:58.764076Z",
     "start_time": "2017-07-13T20:58:52.285801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Previously tokenized recipe corpus\n",
    "# dict of recipe_ID:list of preprocessed, tokenized ingredient phrases\n",
    "with open('recipe_tokens.pkl', 'rb') as f: \n",
    "    recipe_tokens = cPickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-10T22:25:18.993192Z",
     "start_time": "2017-07-10T22:25:18.904828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'228057',\n",
       " [[u'collard', u'greens', u',', u'chopped'],\n",
       "  [u')', u'package', u'hickory-smoked', u'bacon', u',', u'diced'],\n",
       "  [u'butter'],\n",
       "  [u'large', u'onion', u',', u'chopped'],\n",
       "  [u'cubes', u'chicken', u'bouillon', u',', u'crumbled'],\n",
       "  [u'water'],\n",
       "  [u'garlic', u',', u'minced'],\n",
       "  [u'dried', u'oregano'],\n",
       "  [u'ground', u'thyme', u',', u'or', u'to', u'taste'],\n",
       "  [u'dried', u'savory', u',', u'or', u'to', u'taste'],\n",
       "  [u'milk']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_tokens.items()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T03:54:43.394302Z",
     "start_time": "2017-07-11T03:54:43.262246Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # \n",
    "# class LemmaTokenizer(object):\n",
    "#     def __init__(self):\n",
    "#          self.wnl = WordNetLemmatizer()\n",
    "#     def __call__(self, doc):\n",
    "#          return [self.wnl.lemmatize(t) for t in word_tokenize(doc) \\\n",
    "#                  if t not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T03:54:48.235886Z",
     "start_time": "2017-07-11T03:54:48.033094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate stemmer, analyzer \n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T04:12:00.192309Z",
     "start_time": "2017-07-11T04:11:59.627839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate vectorizer for ingredients\n",
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             strip_accents='ascii',\n",
    "                             analyzer=stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T04:12:16.650006Z",
     "start_time": "2017-07-11T04:12:01.492909Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Revert to phrases for stemming/lemmatizing purposes\n",
    "X0 = [[\" \".join(a) for a in b] for b in recipe_tokens.values()]\n",
    "\n",
    "X1 = [\",\".join(a) for a in X0]\n",
    "\n",
    "X2 = vectorizer.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T04:12:16.835029Z",
     "start_time": "2017-07-11T04:12:16.654343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11111, 2791)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T04:12:19.206110Z",
     "start_time": "2017-07-11T04:12:19.095656Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-11T05:31:31.626375Z",
     "start_time": "2017-07-11T05:31:31.269636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconst_mse(target, left, right):\n",
    "    return (array(target - left.dot(right))**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T16:03:20.233569Z",
     "start_time": "2017-07-14T16:03:19.030456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.009462\n",
      "\n",
      "Topic 0:\n",
      "chop pepper and to ground tast onion salt fresh garlic can black oil slice or chees dri minc dice oliv chicken tomato sauc red green\n",
      "\n",
      "Topic 1:\n",
      "sugar white flour butter egg all purpos salt bake extract vanilla ground powder milk brown cream cinnamon soften soda water packag melt chocol chees confection\n"
     ]
    }
   ],
   "source": [
    "# Explore nmf matrices \n",
    "nmf = NMF(n_components = 2)\n",
    "W = nmf.fit_transform(X2)\n",
    "H = nmf.components_\n",
    "n_top_words = 25\n",
    "print(\"Reconstruction error: %f\") %(reconst_mse(X2, W, H))\n",
    "for topic_num, topic in enumerate(H):\n",
    "    print(\"\\nTopic %d:\" % topic_num)\n",
    "    print(\" \".join([features[i] \\\n",
    "            for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With two components, NMF appears to successfully delineate \"sweet\" (topic 0) and \"savory\" (topic 1) items.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_nmf(r):\n",
    "    nmf = NMF(n_components=r)\n",
    "    nmf.fit(X2)\n",
    "    W = nmf.transform(X2)\n",
    "    H = nmf.components_\n",
    "    return nmf.reconstruction_err_\n",
    "\n",
    "error = [fit_nmf(i) for i in range(1,20)]\n",
    "plt.plot(range(1,20), error)\n",
    "plt.xticks(range(1, 20))\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('Reconstruction Errror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T16:15:06.155862Z",
     "start_time": "2017-07-14T16:15:04.826810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "chop can pepper onion and chees fresh tomato garlic green dice ground dri packag chicken slice drain shred black salt oil minc sauc red cream\n",
      "\n",
      "Topic 1:\n",
      "sugar white flour butter egg all purpos salt bake extract vanilla ground powder milk brown cream cinnamon soften soda water packag melt chocol confection chees\n",
      "\n",
      "Topic 2:\n",
      "to tast pepper or ground salt and black oil fresh garlic slice into cut oliv minc onion dri more sauc red larg chicken inch powder\n"
     ]
    }
   ],
   "source": [
    "num_topics = 3\n",
    "nmf = NMF(n_components=num_topics)\n",
    "nmf.fit(X2) \n",
    "W = nmf.transform(X2)\n",
    "H = nmf.components_\n",
    "for topic_num, topic in enumerate(H):\n",
    "    print(\"\\nTopic %d:\" % topic_num)\n",
    "    print(\" \".join([features[i] \\\n",
    "        for i in topic.argsort()[:-n_top_words - 1:-1]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond two topics, it gets harder to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T16:28:32.231699Z",
     "start_time": "2017-07-14T16:28:24.208305Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate vectorizer for ingredients\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             strip_accents='ascii',\n",
    "                             analyzer=stemmed_words)\n",
    "X2_tfidf = tfidf_vectorizer.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T16:28:32.281902Z",
     "start_time": "2017-07-14T16:28:32.233772Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_features = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-14T16:30:55.527286Z",
     "start_time": "2017-07-14T16:30:53.487284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.000293\n",
      "\n",
      "Topic 0:\n",
      "chop pepper ground garlic dri fresh onion minc sauc oil black tomato dice red can chicken oliv green salt and bell slice powder juic vinegar\n",
      "\n",
      "Topic 1:\n",
      "sugar bake flour purpos all white extract egg vanilla butter powder soda milk salt cinnamon brown soften ground confection pack water chocol melt shorten beaten\n",
      "\n",
      "Topic 2:\n",
      "chees packag cream shred can cheddar soup of frozen mix condens sour parmesan drain grate chop mushroom slice milk thaw butter cook soften egg onion\n",
      "\n",
      "Topic 3:\n",
      "to tast or and pepper salt more slice black fresh into as need oliv cut ground oil peel potato butter larg inch lemon garlic thin\n"
     ]
    }
   ],
   "source": [
    "# Explore nmf matrices \n",
    "nmf = NMF(n_components = 4)\n",
    "W = nmf.fit_transform(X2_tfidf)\n",
    "H = nmf.components_\n",
    "n_top_words = 25\n",
    "print(\"Reconstruction error: %f\") %(reconst_mse(X2_tfidf, W, H))\n",
    "for topic_num, topic in enumerate(H):\n",
    "    print(\"\\nTopic %d:\" % topic_num)\n",
    "    print(\" \".join([features[i] \\\n",
    "            for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## term frequency / doc frequency might give more distinct topics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
